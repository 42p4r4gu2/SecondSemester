{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction.\n",
    " On April 15, 1912, the largest passenger liner ever built col-\n",
    "lided with an iceberg during its maiden voyage. When the Titanic sank, 1502 of\n",
    "the 2224 passengers and crew were killed. This sensational tragedy shocked the\n",
    "international community and led to improved safety regulations for ships. One\n",
    "of the reasons that the shipwreck resulted in such a loss of life was that there\n",
    "were not enough lifeboats for the passengers and crew. Although there was an\n",
    "element of luck involved in surviving the sinking, some groups of people were\n",
    "more likely to survive than others.\n",
    "\n",
    "Data.\n",
    " The titanic.csv ﬁle in the directory data contains data for 887 of\n",
    "the real Titanic passengers. Each row represents one passenger. The columns\n",
    "describe attributes about the passengers, including whether they survived (S),\n",
    "their passenger class (C), their gender (G), their age (A), and the fare they paid\n",
    "(F).\n",
    "\n",
    "Column S encodes survival as 1 and death as 0; column G encodes male as\n",
    "0 and female as 1. Passenger classes C are 1 (top), 2 (middle), and 3 (bottom).\n",
    "Task. Write a 1-nearest neighbor classiﬁer using NumPy to predict whether\n",
    "a Titanic passenger survived or not. Follow the instructions in the notebook\n",
    "titanic.ipynb."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset\n",
    "\n",
    "1. **S** survived (1 survived, 0 drowned)\n",
    "2. **C** passenger-class (1 upper, 2 middle, 3 lower)\n",
    "3. **G** gender (0 male, 1 female)\n",
    "4. **A** age\n",
    "5. **F** fare\n",
    "\n",
    "The first column `S` of the Titanic dataset represents the class label. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Load Data\n",
    "\n",
    "The next cell reads the Titanic dataset and stores the table in the 2D array `Z`. Rows represent examples and columns represent features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      3.      0.     22.      7.25  ]\n",
      " [ 1.      1.      1.     38.     71.2833]\n",
      " [ 1.      3.      1.     26.      7.925 ]\n",
      " ...\n",
      " [ 0.      3.      1.      7.     23.45  ]\n",
      " [ 1.      1.      0.     26.     30.    ]\n",
      " [ 0.      3.      0.     32.      7.75  ]]\n"
     ]
    }
   ],
   "source": [
    "file = './data/titanic.csv'\n",
    "Z = np.loadtxt(file, skiprows=1, delimiter=',')\n",
    "print(Z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Split Data\n",
    "\n",
    "Write a function that accepts two arguments: a dataset `Z` and a parameter `test_size`. The function randomly splits the dataset `Z` into two sets: a training set and a test set. The `test_size` parameter specifies the proportion of the data in `Z` that should be allocated to the test set. The function returns both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(Z, test_size=0.2):\n",
    "    num_lines = int((test_size*Z.shape[0])//1)\n",
    "    indices = np.random.choice(Z.shape[0], num_lines, replace=False)\n",
    "    test_data = Z[indices]\n",
    "    train_data = np.delete(Z, indices, axis=0)\n",
    "    return (test_data, train_data)\n",
    "\n",
    "data_tuple = split(Z)\n",
    "test_data = data_tuple[0]\n",
    "train_data = data_tuple[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Exploration\n",
    "\n",
    "Write a function `info` that takes a dataset as 2D array and the index of the class label as input and displays the following information:\n",
    "\n",
    "+ Number of examples\n",
    "+ Number of features (including class label)\n",
    "+ Numer of unique class labels\n",
    "+ Total Number of values\n",
    "+ Type of elements in the dataset\n",
    "+ Mean and standard deviation of each feature \n",
    "\n",
    "Additional parameters may be added if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:       342  \n",
      "number of features:       5    \n",
      "number of unique labels:  2    \n",
      "total number of values:   4435 \n",
      "type of all elements      float64\n",
      "Matrix of mean values:    [ 0.38556933  2.30552424  0.35400225 29.47144307 32.30542018]\n",
      "Matrix of std:            [ 0.48672952  0.83619025  0.47820985 14.11394567 49.75397046]\n"
     ]
    }
   ],
   "source": [
    "def info(X, label_index):\n",
    "    mask = X[:,0] == label_index\n",
    "    info_matrix = X[mask]\n",
    "    num_example = len(info_matrix)\n",
    "    num_feature = X.shape[1]\n",
    "    unique_labels = len(np.unique(X[:, 0], axis=0))\n",
    "    total_vals = X.size\n",
    "    type_elem = X.dtype\n",
    "    mean_matrix = np.mean(a=X, axis=0)\n",
    "    sdv_matrix = np.std(a=X, axis=0)\n",
    "    print(f'{\"number of examples: \":25} {num_example:<5}')\n",
    "    print(f'{\"number of features: \":25} {num_feature:<5}')\n",
    "    print(f'{\"number of unique labels: \":25} {unique_labels:<5}')\n",
    "    print(f'{\"total number of values: \":25} {total_vals:<5}')\n",
    "    print(f'{\"type of all elements \":25} {type_elem}')\n",
    "    print(f'{\"Matrix of mean values: \":25} {mean_matrix}')\n",
    "    print(f'{\"Matrix of std: \":25} {sdv_matrix}')\n",
    "\n",
    "    \n",
    "info(Z, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Standardization\n",
    "\n",
    "Implement standardization to scale the feature matrix (excluding class labels) so that each column has a mean of zero and a standard deviation of one.\n",
    "\n",
    "**Note:** Estimate the mean and standard deviation using only the training feature matrix. Then, scale both the training and test feature matrices using the estimated values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82253676 -0.75551073 -0.51645248 ...  0.         22.\n",
      "   7.25      ]\n",
      " [-1.5611412   1.32360794  0.62317631 ...  1.         38.\n",
      "  71.2833    ]\n",
      " [ 0.82253676  1.32360794 -0.23154528 ...  1.         26.\n",
      "   7.925     ]\n",
      " ...\n",
      " [ 0.82253676 -0.75551073 -0.30277208 ...  0.         25.\n",
      "   7.05      ]\n",
      " [ 0.82253676  1.32360794 -1.58485448 ...  1.          7.\n",
      "  23.45      ]\n",
      " [ 0.82253676 -0.75551073  0.19581551 ...  0.         32.\n",
      "   7.75      ]]\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "def standardization(X):\n",
    "    x_samples, x_labels = X.shape\n",
    "    mean_x = np.mean(a=X[:,1:], axis=0)\n",
    "    std_x = np.std(a=X[:,1:], axis=0)\n",
    "    \n",
    "    X_std = (X[:,1:] - mean_x) / std_x\n",
    "    X_std = np.hstack((X_std, X[:,1:]))\n",
    "    print(X_std)\n",
    "    \n",
    "standardization(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Nearest-Neighbor Classifier\n",
    "\n",
    "Write a score function that returns the classification accuracy on the test set using the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation\n",
    "\n",
    "Evaluate the 1-NN classifier with and without data standardization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
