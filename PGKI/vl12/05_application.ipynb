{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Application\n",
    "\n",
    "This notebook serves to provide a first impression of how to use Pandas for data science. \n",
    "\n",
    "For our working example, we will use the `data/india_dirty.csv` dataset. This dataset was taken from [Data analysis: female literacy in India](https://scipython.com/book2/chapter-9-data-analysis-with-pandas/examples/data-analysis-female-literacy-in-india/) and has been modified to illustrate some pandas techniques.\n",
    "\n",
    "Goal of the analysis is to model the relationship between female literacy and the other features provided by the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Content\n",
    "\n",
    "    5.1  Loading the Data\n",
    "    5.2  Inspecting the Data\n",
    "    5.3  Data Cleaning: Removing Irrelevant Features\n",
    "    5.4  Data Cleaning: Correcting the Type of Data\n",
    "    5.5  Data Cleaning: Detecting Missing Data\n",
    "    5.6  Data Cleaning: Handling Missing Data\n",
    "    5.7  Data Cleaning: Handling Duplicates\n",
    "    5.8  Outlier Detection\n",
    "    5.9  Feature Engineering\n",
    "    5.10 Exploring the Data\n",
    "    5.11 Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### 5.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/india_dirty.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** We can convert a pandas DataFrame to a NumPy ndarray by calling the `to_numpy()` method of `.values` on the DataFrame. This allows us to explore the data using NumPy functions and methods. Example: The call\n",
    "\n",
    "```python\n",
    "    data_1 = df.to_numpy()\n",
    "    data_2 = df.values\n",
    "```\n",
    "\n",
    "convert DataFrame `df` to the NumPy ndarray `data`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.2 Inspecting the Data\n",
    "\n",
    "After loading the data into a Pandas DataFrame, it is important to inspect it to get a better understanding of its structure and contents. Common DataFrame methods for inspecting the data are:\n",
    "\n",
    "```python\n",
    "    df.head(3)         # print first 3 rows (5 is default)\n",
    "    df.tail(3)         # print last 3 rows (5 is default)\n",
    "    df.info()          # print summary \n",
    "    df.describe()      # print descriptive statistics of the data\n",
    "    df.shape           # return number of rows and columns \n",
    "    df.index           # print index labels\n",
    "    df.columns         # print column labels\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 `df.head`\n",
    "\n",
    "The `df.head` method is useful for quickly getting an overview and seeing a sample of the data without having to view the entire DataFrame, which can be helpful when working with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State/UT</th>\n",
       "      <th>TIN</th>\n",
       "      <th>Code</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Area (km2)</th>\n",
       "      <th>Male Literacy (%)</th>\n",
       "      <th>Fertility Rate</th>\n",
       "      <th>Female Literacy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>8</td>\n",
       "      <td>RJ</td>\n",
       "      <td>35550997</td>\n",
       "      <td>32997440</td>\n",
       "      <td>342239</td>\n",
       "      <td>80.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>23</td>\n",
       "      <td>MP</td>\n",
       "      <td>37612306</td>\n",
       "      <td>35014503</td>\n",
       "      <td>308245</td>\n",
       "      <td>80.53</td>\n",
       "      <td>3.3</td>\n",
       "      <td>60.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>27</td>\n",
       "      <td>MH</td>\n",
       "      <td>58243056</td>\n",
       "      <td>54131277</td>\n",
       "      <td>307713</td>\n",
       "      <td>89.82</td>\n",
       "      <td>1.9</td>\n",
       "      <td>75.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>9</td>\n",
       "      <td>UP</td>\n",
       "      <td>104480510</td>\n",
       "      <td>95331831</td>\n",
       "      <td>240928</td>\n",
       "      <td>79.24</td>\n",
       "      <td>3.7</td>\n",
       "      <td>59.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>1</td>\n",
       "      <td>JK</td>\n",
       "      <td>6640662</td>\n",
       "      <td>5900640</td>\n",
       "      <td>222236</td>\n",
       "      <td>87.26</td>\n",
       "      <td>2.2</td>\n",
       "      <td>86.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State/UT  TIN Code  Male Population  Female Population  \\\n",
       "0          Rajasthan    8   RJ         35550997           32997440   \n",
       "1     Madhya Pradesh   23   MP         37612306           35014503   \n",
       "2        Maharashtra   27   MH         58243056           54131277   \n",
       "3      Uttar Pradesh    9   UP        104480510           95331831   \n",
       "4  Jammu and Kashmir    1   JK          6640662            5900640   \n",
       "\n",
       "   Area (km2) Male Literacy (%)  Fertility Rate  Female Literacy (%)  \n",
       "0      342239             80.51             NaN                52.66  \n",
       "1      308245             80.53             3.3                60.02  \n",
       "2      307713             89.82             1.9                75.48  \n",
       "3      240928             79.24             3.7                59.26  \n",
       "4      222236             87.26             2.2                86.23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Irrelevant features**\n",
    "\n",
    "We identify the following features as irrelevant for our analysis:\n",
    "\n",
    "+ tax identification number (TIN) \n",
    "\n",
    "+ state code\n",
    "\n",
    "We will discard these features in the *data cleaning* step. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Missing values**\n",
    "\n",
    "We happen to identify a missing value in the first row (fertility rate of Rajasthan). We need to check for other missing values and deal with them appropriately. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Missing features**\n",
    "\n",
    "Potentially useful features that are missing are \n",
    "\n",
    "+ population density: how do fertility and literacy rates relate to density?\n",
    "\n",
    "+ total literacy rate: what is the total literacy rate of a state?\n",
    "\n",
    "We will add potentially useful features to our DataFrame object in the *feature engineering* step. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 `df.info`\n",
    "\n",
    "The `df.info()` method provides a summary of the DataFrame, including the \n",
    "\n",
    "+ number of entries\n",
    "\n",
    "+ column names\n",
    "\n",
    "+ data types\n",
    "\n",
    "+ memory usage \n",
    "\n",
    "This information can be useful when deciding how to clean and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   State/UT             37 non-null     object \n",
      " 1   TIN                  37 non-null     int64  \n",
      " 2   Code                 37 non-null     object \n",
      " 3   Male Population      37 non-null     int64  \n",
      " 4   Female Population    37 non-null     int64  \n",
      " 5   Area (km2)           37 non-null     int64  \n",
      " 6   Male Literacy (%)    36 non-null     object \n",
      " 7   Fertility Rate       34 non-null     float64\n",
      " 8   Female Literacy (%)  35 non-null     float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erroneous and missing data**\n",
    "\n",
    "The output shows that \n",
    "\n",
    "+ the table consists of 37 rows and 9 columns\n",
    "\n",
    "+ type of column 'male literacy' should be numeric but is object\n",
    "\n",
    "+ column 'male literacy' has one missing value\n",
    "\n",
    "+ column 'fertility rate' has three missing values\n",
    "\n",
    "+ column 'female literacy' has two missing values\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The 'male literacy' column could not be recognized as numeric because it includes a non-numeric entry. This issue will be addressed during the data cleaning step, where we will correct or remove any missing or erroneous data. Similarly, handling missing values is also an important part of the data cleaning process. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.3 Data Cleaning: Removing Irrelevant Features\n",
    "\n",
    "As part of the data cleaning process, we want to remove the irrelevant columns 'TIN' and 'Code' from our DataFrame. For this, we use the `drop()` method.\n",
    "\n",
    "To drop a single column, you can call the `drop()` method and pass the name of the column you want to drop as the first argument, along with the `axis` parameter set to `1` to indicate that you want to drop a column. Here's an example of how you can drop a column named `'column_name'` from a DataFrame `df`:\n",
    "\n",
    "```python\n",
    "    df = df.drop('column_name', axis=1)\n",
    "```\n",
    "\n",
    "If you want to drop multiple columns at once, you can pass a list of column names to the `drop()` method. Here's an example of how you can drop two columns named `'column_1'` and `'column_2'` from a DataFrame `df`:\n",
    "\n",
    "```python\n",
    "    df = df.drop(['column_1', 'column_2'], axis=1)\n",
    "```\n",
    "\n",
    "In our case, we can use this method to remove the 'TIN' and 'Code' columns from our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   State/UT             37 non-null     object \n",
      " 1   Male Population      37 non-null     int64  \n",
      " 2   Female Population    37 non-null     int64  \n",
      " 3   Area (km2)           37 non-null     int64  \n",
      " 4   Male Literacy (%)    36 non-null     object \n",
      " 5   Fertility Rate       34 non-null     float64\n",
      " 6   Female Literacy (%)  35 non-null     float64\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop irrelevant columns\n",
    "df = df.drop(['TIN','Code'], axis=1)\n",
    "\n",
    "# inspect data\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.4 Data Cleaning: Correcting the Type of Data\n",
    "\n",
    "We notice that the male literacy column is not of numeric type, although we expected it to be. The `to_numeric()` method will attempt to convert non-numeric objects (such as strings) to integers or floats as appropriate.\n",
    "\n",
    "**Example:** \n",
    "\n",
    "```python\n",
    "df['column_name'] = pd.to_numeric(df['column_name'], errors='coerce')\n",
    "```\n",
    "\n",
    "Here, `column_name` is the name of the column to be converted. The `errors` argument determines how the function handles invalid parsing:\n",
    "\n",
    "+ `errors='coerce'`: invalid parsing will be set as `NaN`\n",
    "+ `errors='raise'`: an exception will be raised for invalid parsing\n",
    "+ `errors='ignore'`: the original value will be returned if parsing is invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Male Literacy (%)'] = pd.to_numeric(df['Male Literacy (%)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   State/UT             37 non-null     object \n",
      " 1   Male Population      37 non-null     int64  \n",
      " 2   Female Population    37 non-null     int64  \n",
      " 3   Area (km2)           37 non-null     int64  \n",
      " 4   Male Literacy (%)    35 non-null     float64\n",
      " 5   Fertility Rate       34 non-null     float64\n",
      " 6   Female Literacy (%)  35 non-null     float64\n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting the data type of the male literacy column to `float64`, we note that the number of missing values has increased from one to two. This is because one of the values in the column was a string 'xxx', which could not be parsed as a numeric value and resulted in a `NaN` value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.5 Data Cleaning: Detecting Missing Data\n",
    "\n",
    "We have identified missing data in the following columns of our DataFrame:\n",
    "\n",
    "+ male literacy\n",
    "\n",
    "+ female literacy\n",
    "\n",
    "+ fertility rate\n",
    "\n",
    "To detect missing values, we can use the `df.isna()` method. This method returns a boolean DataFrame of the same shape as `df`, where missing values, `None`, and `np.NaN` are mapped to `True` and all other values, including empty strings `''` and `np.inf`, are mapped to `False`.\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "+ A missing value is represented by the absence of any character between two commas. The space ` ` and  the empty string `''` are treated as string values and not as missing values.\n",
    "\n",
    "+ `df.isnull()` is an alias of `df.isna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna()                         # returns boolean object of the same size as df\n",
    "# df.loc[:, df.isna().any()]        # returns columns with missing data (not very useful)\n",
    "# df[df.isna().any(axis=1)]         # returns rows with missing data\n",
    "# df.isna().sum()                   # returns number of missing values for each column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 5.6 Data Cleaning: Handling Missing Data\n",
    "\n",
    "This step involves identifying and correcting or removing missing data. Two simple techniques to handle missing values are **deletion** and **imputation**.\n",
    "\n",
    "Imputation refers to the process of replacing missing or correcting incomplete values in the dataset with  estimates based on other available information. Simple techniques for replacing missing values include imputing the mean or median of a feature. More sophisticated imputation techniques include regression and interpolation.\n",
    "\n",
    "#### 5.6.1 Imputing Values\n",
    "\n",
    "We will first impute values for the missing data in the `Fertility Rate` column. This task is critical and should be done with care (see note). In this example, we will take a simple approach and impute the median fertility rate. Our primary concern is to introduce the `df.fillna()` method to fill missing values with a specified value.\n",
    "\n",
    "**Note:** Imputing the right values for missing data is critical because it can have a significant impact on the results of your analysis. Imputing incorrect or inappropriate values can introduce bias or distortions into the dataset, leading to inaccurate or misleading results. For example, imputing missing values using the mean or median of a column can artificially reduce the variance of the data and make it appear more homogeneous than it actually is. This can affect the performance of statistical tests and machine learning models, leading to incorrect conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median fertility rate\n",
    "median_fertility = df['Fertility Rate'].median()\n",
    "print('median fertility rate:', median_fertility)\n",
    "\n",
    "# impute median\n",
    "df['Fertility Rate'] = df['Fertility Rate'].fillna(median_fertility)\n",
    "\n",
    "# show number of missing values for each column\n",
    "df.isna().sum() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2 Deleting rows with missing values\n",
    "\n",
    "If imputation is not possible or if the remaining missing values are not significant for your analysis, you can then drop the rows with missing values using the `dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State/UT               0\n",
       "Male Population        0\n",
       "Female Population      0\n",
       "Area (km2)             0\n",
       "Male Literacy (%)      0\n",
       "Fertility Rate         0\n",
       "Female Literacy (%)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with at least one missing value\n",
    "df = df.dropna()\n",
    "\n",
    "# show number of missing values for each column\n",
    "df.isna().sum() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.7 Data Cleaning: Handling Duplicates\n",
    "\n",
    "Duplicate data can arise in a dataset for several reasons. In some cases, duplicate data may be valid and represent the distribution of the data (e.g., weight and height of people). In other cases, duplicate data can compromise the integrity of the dataset.\n",
    "\n",
    "The `df.duplicated()` method detects duplicate records in a dataset. This method returns a boolean Series indicating whether each row is a duplicate of another row. A value of `True` indicates that the row is a duplicate, while a value of `False` indicates that the row is unique.\n",
    "\n",
    "Chaining the `df.duplicated()` method with the `.sum()` method returns the number of duplicates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates can be dropped by using the `df.drop_duplicates()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all duplicate rows except for the first occurence\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# final inspection\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.8 Outlier Detection\n",
    "\n",
    "Outliers can have a negative impact on statistical analysis and the training process of machine learning algorithms. As such, it’s important to detect and handle outliers during the data preprocessing stage.\n",
    "\n",
    "One way to get a first impression of the data distribution is to use the `df.describe()` method. This method generates descriptive statistics that summarize the central tendency, dispersion, and shape of the distribution of a dataset.\n",
    "\n",
    "If you identify any suspicious columns, you can further inspect them using various methods such as box plots, scatter plots, or z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are most likely to be found in the 'Area' column. The minimum and maximum values substantially differ from the mean and the percentiles. A similar observation can be made with the population columns.  A closer look may be necessary.\n",
    "\n",
    "\n",
    "**Handling Outliers**\n",
    "\n",
    "Although dealing with outliers is beyond the scope of this notebook, we will provide a brief overview of different techniques.\n",
    " \n",
    "There are several ways to handle outliers, depending on the specifics of the dataset and the analysis being performed. Some common methods for dealing with outliers include:\n",
    "\n",
    "+ Removing (trimming) the outliers: remove the outliers from the dataset if they are not significant to the analysis or if they represent errors or bad data.\n",
    "\n",
    "+ Quantile-based flooring and capping: cap the values of the data at a certain quantile to reduce the impact of extreme values.\n",
    "\n",
    "+ Imputation: impute the values of the outliers using various techniques such as for missing values. \n",
    "\n",
    "+ Transform the data: use techniques such as scaling, log transformation, or cube-root normalization to reduce the impact of outliers.\n",
    "\n",
    "It is important to carefully consider the potential impact of dealing with outliers.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.9 Feature Engineering\n",
    "\n",
    "When we examined the data, we realized that potentially useful features are missing for our analysis:\n",
    "\n",
    "+ population density: how do fertility and literacy rates relate to population density?\n",
    "\n",
    "+ total literacy rate: what is the total literacy rate of a state?\n",
    "\n",
    "To address these gaps, we can perform feature engineering to create new features that capture this information. As an example, we will add the total population as an auxiliary feature and calculate the population density."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.9.1 Total population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column\n",
    "df['Population'] = df['Male Population'] + df['Female Population']\n",
    "\n",
    "# check the total population\n",
    "total_pop = df['Population'].sum()\n",
    "print(f'total population: {total_pop:,d}')\n",
    "\n",
    "# inspect data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5.9.2 Population Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column\n",
    "df['Density'] = df['Population'] / df['Area (km2)']\n",
    "\n",
    "# inspect data\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.10 Exploring the Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.10.1 Pairwise Scatterplot\n",
    "\n",
    "Pairwise scatterplots (see UE 11) are useful for quickly visualizing relationships between pairs of variables and can help to identify trends, correlations, and outliers. To create a pairwise scatterplot, we use the `sns.pairplot()` function from the Seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install seaborn -y           # uncomment for installing seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the plot indicates (the partly obvious) correlations between \n",
    "\n",
    "+ male and female literacy\n",
    "\n",
    "+ fertility rate and female literacy\n",
    "\n",
    "+ population and area\n",
    "\n",
    "+ population, female population, and male population\n",
    "\n",
    "In addition, we see that the population of one state (Uttar Pradesh) is an outlier. \n",
    "\n",
    "Based on these results, it may be possible to predict female literacy using only male literacy and fertility rate as predictors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.10.2 Correlations\n",
    "\n",
    "To verify the visual observations obtained from `sns.pairplot`, we can compute the correlation coefficients between the variables. The correlation coefficient measures the strength and direction of the linear relationship between two variables, with values ranging from -1 to 1. Values close to -1 or 1 indicate a strong correlation, while values close to 0 indicate a weak correlation. We can use the `df.corr()` method to compute the correlation coefficients for the variables in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns with numeric data\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(corr_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `df.corr()` method to compute the correlation coeffcient between two columns of a DataFrame. For example, to compute the correlation coefficient between fertiltiy rate and female literacy, call: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fertility Rate'].corr(df['Female Literacy (%)'])  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "A coefficient of -0.6 indicates a moderate negative linear relationship between fertility rate and female literacy. \n",
    "\n",
    "It is important to note that this correlation does not imply causation. While the data suggests that higher fertility rates are associated with lower female literacy, it does not necessarily mean that high fertility rates cause low female literacy. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.11 Linear Regression\n",
    "\n",
    "As a final step, we will use sklearn's linear regression [[>](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)] to predict female literacy using male literacy and fertility rate as predictors. We will first select the relevant columns from the DataFrame and then convert the data to a NumPy ndarray. Once we have the data in the desired format, we can apply linear regression to make our predictions. Note that we are keeping the setup simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Select columns and convert to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Male Literacy (%)', 'Fertility Rate', 'Female Literacy (%)']].values\n",
    "print('shape:', data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Split numpy array into feature matrix `X` and label vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "r2_score = lr.score(X, y)\n",
    "\n",
    "print(f'train r2: {r2_score:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "**Interpretation:** The coefficient of determination $R^2$ is explained in the sklearn documentation [[>](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)]\n",
    "\n",
    "The best possible $R^2$ value is 1.0. An $R^2$ score of 0.76 means that approximately 76% of the variance in the dependent variable can be explained by the independent variables in the model. This suggests that the model has a relatively good fit to the data, although there is still some unexplained variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
